%*******************************************************************************
%*********************************** Introduction ******************************
%*******************************************************************************
% This is the introduction where you should introduce your work.  In
% general the thing to aim for here is to describe a little bit of the
% context for your work --- why did you do it (motivation), what was the
% hoped-for outcome (aims) --- as well as trying to give a brief
% overview of what you actually did.

% It's often useful to bring forward some ``highlights'' into
% this chapter (e.g.\ some particularly compelling results, or
% a particularly interesting finding).

% It's also traditional to give an outline of the rest of the
% document, although without care this can appear formulaic
% and tedious. Your call.
\begin{savequote}[75mm]
  Since I have always preferred making plans to executing them, I have
  gravitated towards situations and systems that, once set into operation,
  could create music with little or no intervention on my part. That is to say,
  I tend towards the roles of planner and programmer, and then become an
  audience to the results.
  \qauthor{\citet{alpern1995techniques}}
\end{savequote}

\chapter{Introduction}

\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi

%********************************** %First Section  **************************************
Bringing together ideas from language modelling, deep learning, and music
psychology, we develop a generative model for music and conduct a large-scale
subjective evaluation. Our results validate our success: participants were only
5\% more likely to identify an original Bach composition from a sample from
BachBot. To our knowledge, no prior work in automatic composition has carried
out a study at this scale.

Our fundamental question is this: have advances in deep learning enabled
construction of musical models capable of deceiving human listeners. To answer this
question, we build a model incorporating the current state-of-the-art in deep
neural sequence modelling and conduct a large-scale musical Turing test. Our
results convincingly suggest an affirmitive answer.

Our contributions incude:
\begin{enumerate}
    \item A note-by-note sequential representation for polyphonic music
      amenable to processing with standard sequence models
    \item A rigorous investigation of how recent deep learning advances such
        how as dropout \citep{srivastava2014dropout}, batch normalization
        \citep{ioffe2015batch}, and new RNN architectures can be applied to
        improve probabilistic modelling of music data
    \item A connectionist model for Bach chorales which avoids domain-specific
      feature engineering and is capable of composing, completing, harmonizing,
      and scoring polyphonic scores
    \item The first large-scale music Turing test with over \mynote{XXX} participants
\end{enumerate}

While deep learning has revolutionized computer vision and natural language
processing, its applications to other domains are still emerging. This
dissertation is concerned with the applications of deep learning to a new
problem domain: music scores.

In this work, we investigate how sequence probability models parameterized by
deep recurrent neural networks can be used as generative models over scores of
music. Such a model has a variety of applications within computational music
theory. The aim of this work is to investigate applications on two particular
tasks: melody harmonization and automatic composition.

Every aspiring music theorist is at some point tasked with composing simple
pieces of music in order demonstrate understanding of the harmonic rules of
Western classical music. These pedagogical exercises often include
harmonization of chorale melodies, a task which is viewed as sufficiently
constrained to allow a composer's basic technique to be judged. A generative
model for music scores can be applied to this task by conditioning on the
melody line and sampling the conditional distribution for possible
harmonizations.

A more difficult task is automatic composition, where the composer is tasked
with producing an original composition of a particular musical style. The open
nature of this task enables a composer to demonstrate both their
understanding of music theory as well as their creativity. However, this lack of
constraints and loose definition of musical style makes it more difficult to
evaluate the quality of the output. To apply a generative model towards this
task, we can train the model to assign larger probability mass to stylistically
similar scores and then sample the model to generate a novel composition.

While our modeling framework is capable of modeling any encoded music
score, we focus our study on chorales by Johann Sebasian Bach. These provide
a relatively large corpus by a single composer, are well understood by music
theorists, and are routinely used when teaching music theory.
The aim is to build an automatic music composition system capable of imitating
Bach's compositional style on both harmonization and automatic composition tasks.

We will examine how design decisions made when constructing probability models
over music affect the musical characteristics of generated samples, investigate
practical matters encountered with parallel training and sampling across
multiple GPUs, and benchmark how well our final system performs on human test
subjects.

\mynote{Mark: this speaks to an important part of the why for this project
and could do with setting in relief.}

With advances in computing and progress in modeling methods and algorithms,
computational modeling has started to provide novel insights into various
musical phenomena. By offering a method for quantitatively testing theories,
it can help us to learn more about the various cognitive and perceptual processes
related to music comprehension, production, and style.
