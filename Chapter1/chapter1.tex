%*******************************************************************************
%*********************************** Introduction ******************************
%*******************************************************************************
% This is the introduction where you should introduce your work.  In
% general the thing to aim for here is to describe a little bit of the
% context for your work --- why did you do it (motivation), what was the
% hoped-for outcome (aims) --- as well as trying to give a brief
% overview of what you actually did.

% It's often useful to bring forward some ``highlights'' into
% this chapter (e.g.\ some particularly compelling results, or
% a particularly interesting finding).

% It's also traditional to give an outline of the rest of the
% document, although without care this can appear formulaic
% and tedious. Your call.

\chapter{Introduction}

\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi

%********************************** %First Section  **************************************
\begin{quote}
  What can we say about the perception of music by the silent majority of
  listeners, those for whom music is written but who neither create music nor
  can articulate their musical experience? How do they acquire their
  demonstrably sophisticated intuitions about music patterns
  typical of their culture? Experiments in the cognitive psychology of music
  have cast some light on the first question. Recent developments in neural net learning
  now enables us to explore the second.
\end{quote} \citet{bharucha1989modeling}

Bringing together ideas from language modelling, deep learning, and music
psychology, we develop a generative model for music and conduct a large-scale
subjective evaluation. Our results validate our success: participants were only
5\% more likely to identify an original Bach composition from a sample from
BachBot. To our knowledge, no prior work in automatic composition has carried
out a study at this scale.

Our fundamental question is this: have advances in deep learning enabled
construction of musical models capable of deceiving human listeners. To answer this
question, we build a model incorporating the current state-of-the-art in deep
neural sequence modelling and conduct a large-scale musical Turing test. Our
results suggest an undeniable yes.

Our contributions incude:
\begin{enumerate}
    \item A note-by-note sequential representation for polyphonic music amenable to processing with
        standard sequence models
    \item A rigorous investigation of how recent deep learning advances such
        how as dropout \citep{srivastava2014dropout}, batch normalization
        \citep{ioffe2015batch}, and new RNN architectures can be applied to
        improve probabilistic modelling of music data
    \item A connectionist model for Bach chorales which avoids domain-specific
      feature engineering and is capable of composing, completing, harmonizing,
      and scoring polyphonic scores
    \item The first large-scale music Turing test with over \todo{XXX} participants
\end{enumerate}

While deep learning has revolutionized computer vision and natural language
processing, its applications to other domains are still emerging. This
dissertation is concerned with the applications of deep learning to a new
problem domain: music scores.

In this work, we investigate how sequence probability models parameterized by
deep recurrent neural networks can be used as generative models over scores of
music. Such a model has a variety of applications within computational music
theory. The aim of this work is to investigate applications on two particular
tasks: melody harmonization and automatic composition.

Every aspiring music theorist is at some point tasked with composing simple
pieces of music in order demonstrate understanding of the harmonic rules of
Western classical music. These pedagogical exercises often include
harmonization of chorale melodies, a task which is viewed as sufficiently
constrained to allow a composer's skill to be judged. A generative model
for music scores can be applied to this task by conditioning on the melody
line and sampling the conditional distribution for possible harmonizations.

A more difficult task is automatic composition, where the composer is tasked
with producing an original composition of a particular musical style. The open
nature of this task enables a composer to simultaneously demonstrate their
creativity along with understanding of music theory. However, this lack of
constraints and loose definition of musical style makes it more difficult to
evaluate the quality of the output. To apply a generative model towards this
task, we can train the model to assign larger probability mass to stylistically
similar scores and then sample the model to generate a novel composition.

While our modeling framework is capable of modeling any MIDI-encodeable music
score, we focus our study on chorales by Johann Sebasian Bach. These provide
a relatively large corpus by a single composer, are well understood by music
theorists, and are routinely used when teaching music theory.
The aim is to build an automatic music composition system capable of imitating
Bach's compositional style on both harmonization and automatic composition tasks.

We will examine how design decisions made when constructing probability models
over music affect the musical characteristics of generated samples, investigate
practical matters encountered with parallel training and sampling across
multiple GPUs, and benchmark how well our final system performs on human test
subjects.

With advances in computing and progress in modeling methods and algorithms,
computational modeling has started to provide novel insights into varios
musical phenomena. By offering a method for quantitatively testing theories,
it can help us to learn more about the various cognitive and perceptual processes
related to music comprehension, production, and style.

Lorem Ipsum is simply dummy text of the printing and typesetting industry (see
\cref{section1.3})\citep{AAB95,Con90,LM65}.

A {\em \LaTeX{} class file}\index{\LaTeX{} class file@LaTeX class file} is a
file, which holds style information for a particular \LaTeX{}.

\begin{align}
CIF: \hspace*{5mm}F_0^j(a) = \frac{1}{2\pi \iota} \oint_{\gamma} \frac{F_0^j(z)}{z - a} dz
\end{align}

\nomenclature[z-cif]{$CIF$}{Cauchy's Integral Formula}                                % first letter Z is for Acronyms
\nomenclature[a-F]{$F$}{complex function}                                                   % first letter A is for Roman symbols
\nomenclature[g-p]{$\pi$}{ $\simeq 3.14\ldots$}                                             % first letter G is for Greek Symbols
\nomenclature[g-i]{$\iota$}{unit imaginary number $\sqrt{-1}$}                      % first letter G is for Greek Symbols
\nomenclature[g-g]{$\gamma$}{a simply closed curve on a complex plane}  % first letter G is for Greek Symbols
\nomenclature[x-i]{$\oint_\gamma$}{integration around a curve $\gamma$} % first letter X is for Other Symbols
\nomenclature[r-j]{$j$}{superscript index}                                                       % first letter R is for superscripts
\nomenclature[s-0]{$0$}{subscript index}                                                        % first letter S is for subscripts

\nomenclature[z-DEM]{DEM}{Discrete Element Method}
\nomenclature[z-FEM]{FEM}{Finite Element Method}
\nomenclature[z-PFEM]{PFEM}{Particle Finite Element Method}
\nomenclature[z-FVM]{FVM}{Finite Volume Method}
\nomenclature[z-BEM]{BEM}{Boundary Element Method}
\nomenclature[z-MPM]{MPM}{Material Point Method}
\nomenclature[z-LBM]{LBM}{Lattice Boltzmann Method}
\nomenclature[z-MRT]{MRT}{Multi-Relaxation
Time}
\nomenclature[z-RVE]{RVE}{Representative Elemental Volume}
\nomenclature[z-GPU]{GPU}{Graphics Processing Unit}
\nomenclature[z-SH]{SH}{Savage Hutter}
\nomenclature[z-CFD]{CFD}{Computational Fluid Dynamics}
\nomenclature[z-LES]{LES}{Large Eddy Simulation}
\nomenclature[z-FLOP]{FLOP}{Floating Point Operations}
\nomenclature[z-ALU]{ALU}{Arithmetic Logic Unit}
\nomenclature[z-FPU]{FPU}{Floating Point Unit}
\nomenclature[z-SM]{SM}{Streaming Multiprocessors}
\nomenclature[z-PCI]{PCI}{Peripheral Component Interconnect}
\nomenclature[z-CK]{CK}{Carman - Kozeny}
\nomenclature[z-CD]{CD}{Contact Dynamics}
\nomenclature[z-DNS]{DNS}{Direct Numerical Simulation}
\nomenclature[z-EFG]{EFG}{Element-Free Galerkin}
\nomenclature[z-PIC]{PIC}{Particle-in-cell}
\nomenclature[z-USF]{USF}{Update Stress First}
\nomenclature[z-USL]{USL}{Update Stress Last}
\nomenclature[s-crit]{crit}{Critical state}
\nomenclature[z-DKT]{DKT}{Draft Kiss Tumble}
\nomenclature[z-PPC]{PPC}{Particles per cell}

