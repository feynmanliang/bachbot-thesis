\chapter{Discussion, Conclusions, and Future Work}\label{ch:conclusion}
% As you might imagine: summarizes the dissertation, and draws
% any conclusions. Depending on the length of your work, and
% how well you write, you may not need a summary here.

% You will generally want to draw some conclusions, and point
% to potential future work.

% **************************** Define Graphics Path **************************
\ifpdf
    \graphicspath{{Chapter8/Figs/Raster/}{Chapter8/Figs/PDF/}{Chapter8/Figs/}}
\else
    \graphicspath{{Chapter8/Figs/Vector/}{Chapter8/Figs/}}
\fi

\section{Discussion}

From the data generated by \url{bachbot.com}, we are comfortable claiming that
we have successfully accomplished our stated research aim of building an
automatic stylistic composition system indistinguishable from actual Bach. In
the process, we paid conscious effort to avoid allowing prior assumptions
influence model design. By doing so, the performance of our model is a
reflection of its ability to acquire music knowledge from data rather than the
validity of the researcher's prior assumptions.

As a result of using our own music encoding scheme, we were unable to
compare quantitative performance metrics such as log likelihood against many
literature values reported for polyphonic modelling on the \textit{JCB
Chorales} \citep{Allan2005}dataset. While this makes it difficult to evaluate our success, we
affirm that the benefits justify the cost. The goal of our research is automatic
stylistic composition, not probability density modelling. Hence, we prioritize
producing realistic outputs and avoid the quantization distortion introduced by using
\textit{JCB Chorales}, opting instead to evaluate by other means.

Using this sequential encoding scheme, we train a deep LSTM sequential
prediction model and discover that it learns music theoretic concepts without
prior knowledge or explicit supervision. We then propose a method to utilize
the sequential prediction model for harmonization tasks. We acknowledge that
our method is not ideal and discuss better alternatives in future work. Our
harmonization results reveal that this issue is significant and should
be a priority for any follow-up work.

Finally, we leveraged our model to generate harmonizations as well as novel
compositions and used the generated music in a large-scale music Turing test.
Our results here confirm the success of our project.

\section{Summary of contributions}

In this thesis, we make the following contributions:
\begin{itemize}
    \item We introduce sequential encoding scheme for music achieving time-resolution $2\times$
        that of the commonly used \textit{JCB Chorales} \citep{Allan2005} dataset
    \item We demonstrate that a deep LSTM sequential prediction model trained
        on our encoding scheme is capable of composing music less than $9\%$ of
        average listeners can reliably distinguish
    \item Our analysis of the neuron sensitivities within the learned LSTM model
        reveal that common music-theoretic concepts are acquired by the model
        without prior knowledge or supervision, a phenomena which to our
        knowledge has not been reported previously
    \item Performed the largest (to the best of our knowledge as of \today)
        musical Turing test of an automatic composition system, which demonstrated
        that quality data can be collected from voluntary internet surveys
\end{itemize}

In addition, we have open sourced the code for
BachBot\footnote{\url{https://github.com/feynmanliang/bachbot}} as well as our
large-scale music Turing test
framework\footnote{\url{https://github.com/feynmanliang/subjective-evaluation-server}
and \url{https://github.com/feynmanliang/subjective-evaluation-client}}. These
projects have all been received with excitement by the open source community
and plans are in place to transfer the BachBot model to Google Magenta, a team
within TensorFlow \citep{abadi2016tensorflow} which is focused on machine
learning applications within music.

% \section{Conclusions}

% Recall that our journey was prompted by the questions: can the current
% state-of-the-art in deep learning be used to build a pure connectionist
% model which learns to compose in a style indistinguishable from Bach. To
% answer this question, we took numerous ideas from deep learning research
% and built a deep LSTM language model for Bach.

% While our automatic composition model does surprisingly well in composition
% tasks, it underperforms when asked to harmonize fixed melodies: a task which
% music theorists consider significantly easier than automatic composition.

% We plan to continue running the evaluation
% study on \url{bachbot.com} and will update the website as more responses are
% collected. A press release on SoftwareEngineeringDaily (>10K daily users) and a
% feature on Cambridge University's front page are both scheduled to go live
% early September, so we expect a significant increase in the amount of
% responses.

\section{Extensions and Future Work}\label{sec:future-work}

\subsection{Improving harmonization performance}

One significant opportunity for improvement is the harmonization method, which
currently yields less than impressive results
(\cref{sec:harmonization-results}). The problem is that the sequential model is
applied greedily with no accounting of the future constraints present in
harmonization tasks. Our current approach suffers because a $1$-best greedy
approach may make a locally-optimal choice which severely impacts the
likelihoods assigned by the model to the constrained future token outputs.

A potential solution to address this is to apply bidirectional
RNNs\citep{Graves2005} and the sequence to sequence
framework\citep{sutskever2014sequence} to map the constrained parts to the
harmonized parts while accounting for both past and future context. An
attention mechanism similar to \citet{Bahdanau2015} could be introduced on top
of the bidirectional RNN to both enable the model to selectively attend to
specific time intervals within the context as well as provide insight into what
the model deems relevant when generating harmonies.

Another way to account for future constraints is view the problem in a
lattice-based framework. Here, each valid harmonization corresponds to a path
through a lattice constrained by the fixed parts to harmonize against. Under
this lattice based interpretation, our strategy is recognized as a beam search
with beam width $1$. A wider beam-width which maintains $N$-best hypotheses
such as in \citet{liu2014efficient} would allow the model to partially recover
from mistakes made by greedy action selection. Alternatively, a
look-ahead search \citep{norvig1992paradigms} extending to the next fixed token
could also be used to help account for future constraints.

\subsection{Ordering of parts in sequential encoding}

We also found that the performance of harmonizing a single voice was strongly
correlated with the order in which parts within the same frame were encoded
(see \vref{sec:ordering-notes-within-frame}). This suggests that the encoding
scheme may have a more significant impact on model performance than we had
imagined. We expect ordering the parts to be harmonized last should improve the
model as the fixed parts can now provide additional context aiding more
consistent harmony prediction.

\subsection{Extensions to other styles and datasets}

We use the Bach chorales because they are fairly homogeneous, widely available
in a respectable quantity, and well studied by music theorists. However, our
proposed encoding scheme extends to arbitrary degrees of polyphony and musical
style. As evidenced by \vref{fig:harm-twinkle-twinkle}, the learned model is
already able to plausibly harmonize melodies which differ significantly from
Bach's baroque style. An interesting extension would be to further investigate
the limits of of our model's generality and its failure modes by applying
the model to other styles of music.

\subsection{Analyzing results using music theory}

At many points in our work, additional experience in music theory may have
yielded insights not otherwise attainable. One instance of this is in
\vref{fig:responses-name}, where we see that certain samples are virtually
indistinguishable from Bach while others can be identified more than $80\%$ of
the time. It would be valuable to understand what features are present in the
failure cases which make them easy to distinguish, a potential extension for
any interested music theorists.

One last future work we believe to be particularly exciting is to extend
\vref{sec:music-concept-neurons} and perform a statistical analysis of how
closely the model neurons relate to input musical ideas. For instance, the
input could be fixed to some known feature (\eg all perfect cadences in the
tonic key) and the neurons which fire could be examined. Alternatively,
existing understanding can be validated by annotation regions of a score
exhibiting a particular musical quality and searching for neurons with
correlated activity.

