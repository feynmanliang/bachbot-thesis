\chapter{Related Work}
\begin{savequote}[75mm]
  Supposing, for instance, that the fundamental relations of pitched sound in the
  signs of harmony and of musical composition were susceptible of such expression and
  adaptations, the engine might compose elaborate and scientific pieces of music
  of any degree of complexity or extent
  \qauthor{Ada Lovelace \citep{bowles1970musicke}}
\end{savequote}
% This chapter covers relevant (and typically, recent) research
% which you build upon (or improve upon). There are two complementary
% goals for this chapter:
% \begin{enumerate}
%   \item to show that you know and understand the state of the art; and
%   \item to put your work in context
% \end{enumerate}

% Ideally you can tackle both together by providing a critique of
% related work, and describing what is insufficient (and how you do
% better!)

% The related work chapter should usually come either near the front or
% near the back of the dissertation. The advantage of the former is that
% you get to build the argument for why your work is important before
% presenting your solution(s) in later chapters; the advantage of the
% latter is that don't have to forward reference to your solution too
% much. The correct choice will depend on what you're writing up, and
% your own personal preference.


% **************************** Define Graphics Path **************************
\ifpdf
    \graphicspath{{Chapter3/Figs/Raster/}{Chapter3/Figs/PDF/}{Chapter3/Figs/}}
\else
    \graphicspath{{Chapter3/Figs/Vector/}{Chapter3/Figs/}}
\fi

% \mynote{Compare against language modelling research because it's related}

% \mynote{Compare to N-grams; show how it's like an infinite context. One
%     interpretation is to view the hidden state $\h_t$ as an
%     infinite-length prior context window, summarizing all of the prior inputs
%     into into a compact fixed-size vector.}

% Some common trends throughout related works include
% \begin{enumerate}
%   \item Use of domain-specific representations for musical data
%   \item Modelling at multiple resolutions / timescales (\ie chords vs notes)
% \end{enumerate}
% In contrast, we avoid imposing prior knowledge in order to avoid any biases
% and hope that the model will learn the features relevant for good performance.

% \section{Computational Musicology}

% Computational methods applied to large corpora of music was first described in
% \citet{coutinho2005computational}, which termed the phrase ``computational
% musicology.'' Since then, development modern tools have greatly aided research
% efforts. \texttt{music21} \citep{Scott2015} is a Python programming environment
% for performing computations over musical composition data which has been
% utilized for a variety of computational musicology tasks ranging from
% hierarchical modelling of metrical structure \citep{ariza2010modeling}, feature
% generation for downstream machine learning\citep{Cuthbert2011}, and style
% classification \citep{Herlands2014}.

% Focusing on machine learning applications, most research can be
% classified under one or more of the following tasks:
% \begin{enumerate}
%   \item Classification: the style, composer, or other musical attribute is to be classified
%   \item Harmonization: a melody is given and the remaining parts are to be generated
%   \item Completion: given the beginning of a score, the remainder is to be generated
%   \item Automatic Composition: a complete unconstrained score is to be generated
% \end{enumerate}

% There is a vast body of research dealing with music classification tasks,
% including: style classification \citep{Herlands2014,dannenberg1997machine},
% automated harmonic analysis \citep{ni2012end}, information retrieval
% \citep{mandel2006support}, and performer identification
% \citep{stamatatos2005automatic}. However, it is not straightforward to utilize
% work in this area to solve our research goals of music synthesis.
% \mynote{of what?}.

\section{Prior work in automatic composition}

% Research in automatic composition encompasses many music generation ta. Some researchers
% have focused on generating melody lines
% \citep{conklin1995multiple,todd1988sequential,todd1989connectionist},
% others
% have built systems to harmonize or accompany existing melodies
% \citep{ebciouglu1988expert,hild1991harmonet,tsang1991harmonizing,ames1989markov,Allan2005,chuan2007hybrid},
% and some generating full-length novel compositions
% \citep{elman1990finding,spangler1998bach,Eck2002,scirea2016metacompose}.


In a review by \citet{toiviainen2000symbolic}, automatic composition methods
are broadly classified as either symbolic (\eg rule-based expert systems) or
connectionist (\eg neural networks). While our research falls strongly within
the connectionist category, we provide review methods from both categories.

\subsection{Symbolic rule-based methods}

Symbolic methods have been prevalent since the $1960$s
\citep{todd1988sequential} and are appealing because of their high degree of
interpretability. As described by \citet{todd1989connectionist}, symbolic
methods ``enable composers to write down the composition rules employed in
their own creative process and then use a computer to execute these
instructions, enabling assessment of whether the results of the rules held
artistic merit.''

At the heart of many rule-based systems is a collection of rules which are
(recursively) applied to ultimately yield musical notes. While the earliest
rule-based systems required manual specification of rules
\citep{ebciouglu1988expert,cruz1998learning}, later works utilized techniques
such as association rule mining \citep{spangler1998bach}, grammatical inference
\citep{cruz1998learning,quick2014kulitta}, or constraint logic programming
\citep{tsang1991harmonizing} to automatically derive new rules or learn them
from data.

\textit{Experiments in Music Intelligence} (EMI) by
\citet{cope1987experiments,cope1992computer} is one of the first rule-based
composition systems which achieved automatic stylistic composition. Using a
hand-crafted grammar and an augmented transition network
parser \citep{wanner1980atn}, the system was capable of producing music to a
particular genre or author, suggesting that the rules extracted by the system
can capture a sense of musical style. The more recent \textit{Emmy} and
\textit{Emily Howell} projects \citep{cope2013well,cope2010recombinant} extend
EMI by using it as a database of compositions to recombine and build novel
compositions from.

While symbolic methods permit straightforward incorporation of domain-specific
knowledge and a offer high degree of interpretability, they are inherently
biased by their creators' subjective theories on harmony and music cognition.
Furthermore, specification of hand-crafted rules requires music expertise and
the rules may not generalize across different tasks. Additionally, rule-based
methods are brittle to even small amounts of distortion and noise, making them
unsuitable for noisy applications. Furthermore, symbolic methods limit
creativity by disallowing any form of deviation from the defined rules.

\subsection{Early connectionist methods}

Connectionism, also known as parallel distributed processing, refers to systems
built from several simple processing units connected in a network and acting in
cooperation \citep{pdp1986parallel}. Unlike rule based systems, the
connectionist paradigm replaces strict rule-following behaviour with
regularity-learning and generalization \citep{dolson1989machine}.

The earliest connectionist music models utilized note-level Jordan
RNNs\cite{jordan1997serial} for melody generation and harmonization tasks
\citep{todd1988sequential,todd1989connectionist,bharucha1989modeling}.
While they achieved ``varying degrees of success'' \citep{griffith1999musical},
their creators did not conduct any rigorous evaluations.

The next generation of models utilized prior knowledge of music theory to
inform their designs. Mozer's CONCERT \citep{mozer1994neural} system is a BPTT-trained
RNN which models music at two levels of resolution (notes and chords) and
utilizes domain-specific representations for notes
\citep{shepard1982geometrical} and chords \citep{laden1989representation}.
Similarly, HARMONET \citep{hild1991harmonet} also applies domain-specific
knowledge to break down the prediction pipeline into first predicting the Roman
numeral skeleton of a piece followed by chord expansion and ornamentation.
MELONET \citep{feulner1994melonet,hornel1997melonet} builds on top of HARMONET
an additional motif classification sub-network.

A major criticism of these early models is their highly specialized
domain-specific architectures. Despite the connectionist philosophy of learning
from data rather than imposing prior constraints, the models developed are
highly influenced by prior assumptions about the structure of music and
incorporate significant amounts of domain-specific knowledge. Additionally,
these models had difficulties learning the long-term dependencies required for
plausible phrasing structure and motifs. Mozer describes CONCERT as being able
to reproduce scales but ``while the local contours made sense, the pieces were
not musically coherent, lacking thematic structure and having minimal phrase
structure and rhythmic organisation`` (\citet{mozer1994neural}). This problem of
learning long-term dependencies can likely be attributed to the memory cells
used by earlier models, which did not protect against vanishing gradients.

\subsection{Modern connectionist models}

The invention of LSTM in 1997 by \citet{hochreiter1997long} brought on a new
generation of connectionist models which utilized more sophisticated memory
cell implementations. Experiments demonstrated that LSTM possessed many
properties desirable for music applications, such as superior performance
learning grammatical structure \citep{gers2001lstm}, capability to measure time
intervals between events \citep{gers2000recurrent}, and ability to learn to
produce self-sustaining oscillations at a regular frequency
\citet{gers2002learning}. \citet{franklin2006recurrent} evaluated multiple
memory cells on variety of music tasks and concludes: ``while we have found a
task that challenges a single LSTM network, we do not believe that any other
recurrent networks we have used would be able to learn these songs.'''

One of the first applications of LSTM to music was by
\citet{Eck2002,Eck2002-blues}, which used an LSTM to model blues chord
progressions and another LSTM to model melody lines given chords. The authors
reported that LSTM can learn long term music structure such as repeated motifs
without explicit modelling, an improvement over earlier systems such as
HARMONET by \citet{feulner1994melonet} where motifs were explicitly modelled. However,
\citet{Eck2002} used a severely constrained music representation which quantized
to eight notes, neglected the octave numbers for pitch classes, limited the
model to $12$ possible chords, and had ``no explicit way to determine when a
note ends'' \citet{Eck2002}.

% More recently, \citet{sturm2015folk,sturm2016music} trained a character-level
% LSTM on 23,000 folk music scores represented a high-level text format for music
% \citep{abcstandard}. However, the text format they use is unsatisfactory
% because polyphonic scores are encoded one part at a time so notes sounding
% close together in time may appear very far apart in the sequence.
% Unsurprisingly, the authors do not explicitly address polyphony and only present
% monophonic results.

% Many variants of the LSTM architecture have been proposed. Perhaps the most
% well known is the gated recurrent unit (GRU)\citep{cho2014learning}, which
% constrains the input and forget gates to sum to $1$. \citet{Mikolov2015}
% proposed the structurally constrained RNN (SCRN), a simple architecture
% achieving comparable performance to LSTM. Of most relevance to music,
% \citet{Koutnik2014} proposed the clockwork RNN for explicitly modelling
% phenomena occurring at multiple timescales by updating different blocks of
% the hidden state at different periods. Whether these differences matter is
% not definitive: \citet{greff2015lstm} performed 5400 experiments on eight
% different architectures and found no significant difference in performance
% compared to the original LSTM architecture. \citet{Nayebi2015} reports LSTM
% significantly outperform GRUs in music applications.

% CHIME \citep{franklin2001learning} adopted the Jordan RNN from
% \citet{todd1989connectionist} to add a second training phase using actor-critic
% reinforcement learning \citep{sutton1998reinforcement}. The critic is
% constructed using a collection of ``music rules,'' enabling incorporation of
% prior knowledge.

The current state of the art in polyphonic modelling is split between the
RNN-RBM \citep{Boulanger-Lewandowski2012} and RNN-DBN
\citep{goel2014polyphonic} depending on the dataset used for evaluation.
However, both models requires an expensive contrastive divergence sampling step
at each timestep during training. Furthermore, both use a dataset of Bach
chorales which are quantized music to quavers, disallowing shorter-duration
notes such as semiquavers and demisemiquavers.

% In contrast, our work uses the well-understood truncated BPTT
% algorithm for training and quantizes to sixteenth-notes to achieve two-times
% higher time resolution.

% \citet{Lyu2015} extended the RNN-RBM\citep{Boulanger-Lewandowski2012} to use a
% LSTM instead of a RNN for modelling hidden unit time dynamics. Unfortunately,
% it suffers from many of the same problems such as lack of meaningful evaluation.

\section{Automatic stylistic composition}

While symbolic methods for automatic stylistic composition had been previously
researched \citep{cruz1998learning,chuan2007hybrid}, the rising popularity of
connectionist methods coincided with a surge of models for automatically
composing music ranging from baroque \citep{hornel1997melonet} to blues
\citep{Eck2002-blues} to folk music \citep{sturm2015folk}. This correlation is
unsurprising: as connectionist models are trained to capture regularities in
their training data, they are ideally suited for automatically composing music
of a particular style.

\subsection{Applications to Bach chorales}

The Bach chorales have been a popular dataset for automatic composition
research. Early systems primarily focused on chorale harmonization tasks and
include rule-based systems leveraging hand-crafted rules
\citep{ebciouglu1988expert} as well as models learned from data like the
effective Boltzmann machine model \citep{bellgard1994harmonizing}. Hybrids
which learn rules for Bach from data have also been proposed
\citep{spangler1998bach}.

An important work in automatic stylistic composition of Bach chorales is
\citet{Allan2005}, which applied harmonization HMM to generate harmonizations
and a separate ornamentation HMM to fill in semiquavers. Their work is one of
the first to quantitatively evaluate model performance using validation set
cross-entropy and they introduce a dataset of Bach chorales (commonly referred
to as \textit{JSB Chorales} by other work). However, their harmonization
HMM leverages a domain-specific harmonic encoding of chords for hidden states.
Additionally, the dataset they introduced is quantized to quavers and hence
affects all other models utilizing \textit{JSB Chorales}.

The \textit{JSB Chorales} introduced by \citet{Allan2005} has since become a
standard evaluation benchmark routinely used
\citep{Boulanger-Lewandowski2012,pascanu2013construct,bayer2013fast,goel2014polyphonic,zaremba2015empirical}
to evaluate the performance of sequence models on polyphonic music modelling.
The current state-of-the-art on this dataset, as measured by cross-entropy loss
on held-out validation data, is achieved by the RNN-DBN
\citep{goel2014polyphonic}.

While the introduction of the standardized \textit{JSB Chorales} dataset has
helped improve performance evaluation, it does not solve the problem of
measuring the success of an automatic stylistic composition. This is because
the goal of an automatic stylistic composition system is to generate music
which human evaluators find similar to a particular style, not to maximize cross
entropy on unseen test data.

% \citet{Liu2014} applied LSTM to Bach chorales and reports significant gains
% using RProp instead of BPTT, a technique previously utilized by
% MELONET\citep{feulner1994melonet}. However, they erroneously use a mean squared
% error training criterion for a classification task, casting doubts on the
% validity of their experiments.

% \citet{Brien2016} compared RNN models for Bach chorales and found clockwork RNNs to
% yield the lowest validation loss. However, their data format does not permit
% independent articulation of parts. More importantly, the performance margin between
% clockwork RNNs and LSTM was very small ($6.5$ vs $6.75$ cross-entropy loss) and their
% implementation resets the LSTM state when truncating gradients during BPTT, limiting the
% time-range of learned dynamics to be at most the sequence length.

\subsection{Evaluation of automatic composition systems}

This difficulty in evaluating automatic composition systems was first addressed
by \citet{pearce2001towards}. Lack of rigorous evaluation affects many of the
earlier automatic composition systems and complicates performance comparisons. Even
with standard corpuses such as \textit{JSB Chorales}, cross-entropy is still a proxy
to the true measure of success for an automatic stylistic composition system.

In order to obtain a more direct measure of success, researchers have turned to
subjective evaluation by human listeners. \textit{Kulitta}
\citep{quick2014kulitta} is a recent rule-based system whose performance was
evaluated by 237 human participants from Amazon MTurk. However, their
participant pool consists entirely of US citizens (a fault of MTurk in general)
and the data obtained from MTurk is of questionable quality
\citep{downs2010your}. Moreover, their results only indicated that participants
believed \textit{Kulitta} to be closer to Bach than to a random walk. The
use of a large pool of human evaluators represents a step in the right direction.
However, a more diverse participant pool coupled with stronger results would
significantly improve the strength of this work.

Perhaps most relevant to our work is \textit{Racchmaninof} (RAndom Constrained
CHain of MArkovian Nodes with INheritance Of Form) by
\citet{collins2016developing}, an expert system designed for stylistic
automatic composition. The authors evaluate their system on $25$ participants
with a mean of $8.56$ years of formal music training and impressively find that
only $20\%$ of participants performed significantly better than chance. While
we believe this to be one of the most convincing studies on automatic stylistic
composition to date, a few criticisms remain. First, the proposed model is
highly specialized to automatic stylistic composition and is more of a
testament to the author's ability to encode the stylistic rules of Bach than to
the model's ability to learn from data. Additionally, a larger and more diverse
participant group including evaluators of varying skill level would provide
stronger evidence of the model's ability to produce ``Bach-like'' music to
average human listeners.

